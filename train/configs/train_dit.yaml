# Defaults mirrored from scripts/train_dit.py
paths:
  root_dir: data/train
  hic_dirname: Hi-C
  struct_dirname: structure
  vae_ckpt: checkpoints/vae/epoch_040.pt
  save_dir: null  # auto -> checkpoints/dit/<model>-<size> when null

model:
  name: CrossDiT  # choices: CrossDiT, JointAttDiT, MMDiTX
  size: S         # choices: S, B, L, XL
  use_global_cond: true
  gradient_checkpointing: true

training:
  epochs: 50
  batch_size: 8
  lr: 0.0001
  weight_decay: 0.0
  latent_scale: 1.335256
  sample_steps: 50
  warmup_steps: null  # auto -> 0 for CrossDiT else 1000
  clip_grad_norm: 1.0
  scheduler: cosine  # warmup + cosine decay; null keeps constant lr
  num_workers: 4
  pin_memory: true
  precision: fp32

inference_preview:
  batch_size: 10
  cfg_scale: null  # auto -> 1.0 for CrossDiT else 1.5

logging:
  run_name: rf_dit_structure
  wandb_project: rf_dit_structure
